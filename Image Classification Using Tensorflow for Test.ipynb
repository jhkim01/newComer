{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zF9uvbXNVrVY"
   },
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:37:12.098865Z",
     "iopub.status.busy": "2021-01-15T02:37:12.098129Z",
     "iopub.status.idle": "2021-01-15T02:37:18.896813Z",
     "shell.execute_reply": "2021-01-15T02:37:18.897350Z"
    },
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from glob import glob\n",
    "import random\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyDNn9MbIzfT"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "- Image Path(train) : /dataset/train\n",
    "- Image Path(test) : /dataset/test\n",
    "- Image Path(valid) : /dataset/valid\n",
    "- Image Size : Height X Width = 180 X 180\n",
    "- Batch Size : 32\n",
    "- percent of data as validation set : 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:37:29.545783Z",
     "iopub.status.busy": "2021-01-15T02:37:29.545079Z",
     "iopub.status.idle": "2021-01-15T02:37:29.546866Z",
     "shell.execute_reply": "2021-01-15T02:37:29.547292Z"
    },
    "id": "H74l2DoDI2XD"
   },
   "outputs": [],
   "source": [
    "data_dir = ?\n",
    "batch_size = ?\n",
    "img_height = ?\n",
    "img_width = ?\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(?)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(?)\n",
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uoVvxSLJW9m"
   },
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:37:31.621587Z",
     "iopub.status.busy": "2021-01-15T02:37:31.620907Z",
     "iopub.status.idle": "2021-01-15T02:37:32.865693Z",
     "shell.execute_reply": "2021-01-15T02:37:32.866233Z"
    },
    "id": "wBmEA9c0JYes"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.plot(1, 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:37:32.873789Z",
     "iopub.status.busy": "2021-01-15T02:37:32.871863Z",
     "iopub.status.idle": "2021-01-15T02:37:33.397008Z",
     "shell.execute_reply": "2021-01-15T02:37:33.396331Z"
    },
    "id": "2-MfMoenJi8s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wj4FrKxxJkoW"
   },
   "source": [
    "`image_batch`는 `(32, 180, 180, 3)` 형상의 텐서이며, `180x180x3` 형상의 32개 이미지 묶음으로 되어 있습니다(마지막 차원은 색상 채널 RGB를 나타냄). `label_batch`는 형상 `(32,)`의 텐서이며 32개 이미지에 해당하는 레이블입니다.\n",
    "\n",
    "`image_batch` 및 `labels_batch` 텐서에서 `.numpy()`를 호출하여 이를 `numpy.ndarray`로 변환할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:37:33.402383Z",
     "iopub.status.busy": "2021-01-15T02:37:33.401660Z",
     "iopub.status.idle": "2021-01-15T02:37:33.406210Z",
     "shell.execute_reply": "2021-01-15T02:37:33.405559Z"
    },
    "id": "nOjJSm7DKoZA"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GUnmPF4JvEf"
   },
   "source": [
    "## Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:37:33.410915Z",
     "iopub.status.busy": "2021-01-15T02:37:33.410153Z",
     "iopub.status.idle": "2021-01-15T02:37:33.417968Z",
     "shell.execute_reply": "2021-01-15T02:37:33.417444Z"
    },
    "id": "PEYxo2CTJvY9"
   },
   "outputs": [],
   "source": [
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:37:33.424015Z",
     "iopub.status.busy": "2021-01-15T02:37:33.422970Z",
     "iopub.status.idle": "2021-01-15T02:37:39.160937Z",
     "shell.execute_reply": "2021-01-15T02:37:39.160348Z"
    },
    "id": "X9o9ESaJJ502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.094335556 0.8700315\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcUTyDOPKucd"
   },
   "source": [
    "# CNN Archetecture\n",
    "![nn](./asset/simpleCNN_tensorflow.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "- Image Rescale : Convert color scale from 0-255 to 0-1 range.\n",
    "- Image Height : 180 , Image Width : 180 , channel : 3\n",
    "- padding='same'\n",
    "- activation='relu'\n",
    "- Class = 2\n",
    "- 위 4의 CNN 모델을 구성하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(?, input_shape=(?, ?, ?)),\n",
    "  layers.Conv2D(?, ?, ?, ?),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(?, ?,  ?, ?),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(?, ?,  ?, ?),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(?, ?),  \n",
    "  layers.Dense(?)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaKFzz72Lqpg"
   },
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:37:39.257564Z",
     "iopub.status.busy": "2021-01-15T02:37:39.256792Z",
     "iopub.status.idle": "2021-01-15T02:37:39.272892Z",
     "shell.execute_reply": "2021-01-15T02:37:39.272294Z"
    },
    "id": "jloGNS1MLx3A"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:37:39.278984Z",
     "iopub.status.busy": "2021-01-15T02:37:39.278208Z",
     "iopub.status.idle": "2021-01-15T02:37:39.283040Z",
     "shell.execute_reply": "2021-01-15T02:37:39.283453Z"
    },
    "id": "llLYH-BXL7Xe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_4 (Rescaling)     (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 180, 180, 32)      128       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 90, 90, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 90, 90, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 45, 45, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 45, 45, 64)        65600     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 22, 22, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 30976)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                1982528   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,066,882\n",
      "Trainable params: 2,066,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiYHcbvaL9H-"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:37:39.288209Z",
     "iopub.status.busy": "2021-01-15T02:37:39.287535Z",
     "iopub.status.idle": "2021-01-15T02:37:55.165420Z",
     "shell.execute_reply": "2021-01-15T02:37:55.165846Z"
    },
    "id": "5fWToCqYMErH"
   },
   "outputs": [],
   "source": [
    "epochs=5\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyFKdQpXMJT4"
   },
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:37:55.187956Z",
     "iopub.status.busy": "2021-01-15T02:37:55.185573Z",
     "iopub.status.idle": "2021-01-15T02:37:55.453180Z",
     "shell.execute_reply": "2021-01-15T02:37:55.453661Z"
    },
    "id": "jWnopEChMMCn"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtv5VbaVb-3W"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "9개의 이미지를 Predict label과 Actual Label을 비교하여 표시하고 3 X 3의 형태로 이미지를 출력 하시오\n",
    "- 아래 이미지는 출력 예시. 출력이미지와 Predict label이 같지 않아도 상관없습니다.\n",
    "- valid 데이터셋은 ng폴더와 ok폴더로 구성되어 있습니다\n",
    "- Image Height X Image Widht = 180 X 180\n",
    "![simpleCNN_torch2](./asset/visual_torch.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T02:38:17.181722Z",
     "iopub.status.busy": "2021-01-15T02:38:17.180975Z",
     "iopub.status.idle": "2021-01-15T02:38:17.529269Z",
     "shell.execute_reply": "2021-01-15T02:38:17.529736Z"
    },
    "id": "dC40sRITBSsQ"
   },
   "outputs": [],
   "source": [
    "valid_path = glob(\"./dataset/valid/*/*\")\n",
    "num_images = 9\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, iPath in enumerate(valid_path[0:um_images]):\n",
    "    img = keras.preprocessing.image.load_img(iPath, target_size=(?, ?))\n",
    "    \n",
    "    if \"ng\" in iPath:\n",
    "        labels = 0        \n",
    "    else:\n",
    "        labels = 1        \n",
    "    \n",
    "    img_array = keras.preprocessing.image.img_to_array(?)\n",
    "    img_array = tf.expand_dims(?, 0) \n",
    "\n",
    "    predictions = model.predict(?)\n",
    "    score = tf.nn.sigmoid(?)\n",
    "\n",
    "    ax = plt.subplot(?, ?, ?)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Predict :{np.argmax(score)} ---- Actual : {labels}')   \n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일 이름은 본인 이름으로 하여 아래와 같이 저장해주세요\n",
    "![saveImg](./asset/save.JPG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
